{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jzxeyu31aMp"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxC1mi8q2eEU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import heapq\n",
        "import math\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCi0uqsnvjbI"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "from itertools import islice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bVcUChC1cus",
        "outputId": "e392d51e-b998-4e0a-9f68-99f69c7e0d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sudalairajkumar/telugu-nlp\n",
            "License(s): copyright-authors\n",
            "Downloading telugu-nlp.zip to /content\n",
            "  0% 0.00/88.7M [00:00<?, ?B/s]\n",
            "100% 88.7M/88.7M [00:00<00:00, 1.40GB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d sudalairajkumar/telugu-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_24l7FCy1o2O",
        "outputId": "1076ce9b-75db-4e42-84fa-c47afda2035f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  telugu-nlp.zip\n",
            "  inflating: telugu-nlp/telugu_books/telugu_books.csv  \n",
            "  inflating: telugu-nlp/telugu_news/test_telugu_news.csv  \n",
            "  inflating: telugu-nlp/telugu_news/train_telugu_news.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip telugu-nlp.zip -d telugu-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hh5qmnFozrA"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset=load_dataset(\"ai4bharat/IndicCorpV2\",\"indiccorp_v2\",split=\"tel_Telu\",streaming=True)\n",
        "import regex as re\n",
        "\n",
        "def telugu_sentence_tokenizer(text):\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    sentence_endings = r'(?<=[.!?।])\\s'\n",
        "    sentences = re.split(sentence_endings, text)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "def telugu_word_tokenizer(text):\n",
        "    pattern = r'''\n",
        "        (?:\\p{Script=Telugu}(?:[\\p{M}\\u200C\\u200D])*)+                 # Telugu words\n",
        "        | (?:\\d+\\.\\d+)                         # Decimal numbers\n",
        "        | (?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4})    # Dates\n",
        "        | (?:[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}) # Emails\n",
        "        | (?:(?:[https?://|www\\.])[^\\s]+)                  # URLs\n",
        "        | (?:\\d+)                              # Numbers\n",
        "        | [^\\s\\p{L}\\p{N}]                      # Punctuation/symbols\n",
        "    '''\n",
        "    tokens = re.findall(pattern, text, flags=re.VERBOSE)\n",
        "    tokens = [t.replace(\"\\u200c\", \"\").replace(\"\\u200d\", \"\") for t in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UME1tGaRsXUk"
      },
      "outputs": [],
      "source": [
        "def count_ngrams_stream(dataset, max_n, limit=500000):\n",
        "    counts = {n: defaultdict(int) for n in range(1, max_n + 1)}\n",
        "    vocab = set()\n",
        "\n",
        "    for example in islice(dataset, limit):\n",
        "        text = example.get(\"text\") or example.get(\"content\") or \"\"\n",
        "        if not text.strip():\n",
        "            continue\n",
        "        for sentence in telugu_sentence_tokenizer(text):\n",
        "            tokens = ([\"<bos>\"] * (max_n - 1)) + telugu_word_tokenizer(sentence) + [\"<eos>\"]\n",
        "            vocab.update(tokens)\n",
        "\n",
        "            for n in range(1, max_n + 1):\n",
        "                for i in range(len(tokens) - n + 1):\n",
        "                    ngram = tuple(tokens[i:i+n])\n",
        "                    counts[n][ngram] += 1\n",
        "\n",
        "    ngram_counts = {n: dict(counts[n]) for n in range(1, max_n + 1)}\n",
        "\n",
        "    context_counts = {n: ngram_counts.get(n - 1, {}) for n in range(2, max_n + 1)}\n",
        "\n",
        "    return ngram_counts, context_counts, vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pfyzL8nsTF_"
      },
      "outputs": [],
      "source": [
        "class Ngram:\n",
        "    def __init__(self, counts, context_counts, vocab, n):\n",
        "        self.counts = counts\n",
        "        self.context_counts = context_counts\n",
        "        self.vocab = vocab\n",
        "        self.V = len(vocab)\n",
        "        self.n = n\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        if self.n == 1:\n",
        "            return self.counts.get(ngram, 0) / sum(self.counts.values())\n",
        "        context = ngram[:-1]\n",
        "        return self.counts.get(ngram, 0) / max(1, self.context_counts.get(context, 0))\n",
        "\n",
        "    def prob_addone(self, ngram):\n",
        "        if self.n == 1:\n",
        "            return (self.counts.get(ngram, 0) + 1) / (sum(self.counts.values()) + self.V)\n",
        "        context = ngram[:-1]\n",
        "        return (self.counts.get(ngram, 0) + 1) / (self.context_counts.get(context, 0) + self.V)\n",
        "\n",
        "    def prob_addk(self, ngram, k=0.5):\n",
        "        if self.n == 1:\n",
        "            return (self.counts.get(ngram, 0) + k) / (sum(self.counts.values()) + self.V * k)\n",
        "        context = ngram[:-1]\n",
        "        return (self.counts.get(ngram, 0) + k) / (self.context_counts.get(context, 0) + self.V * k)\n",
        "\n",
        "    def prob_addtokentype(self, ngram):\n",
        "        if self.n == 1:\n",
        "            return (self.counts.get(ngram, 0) + random.r) / (sum(self.counts.values()) + self.V)\n",
        "        context = ngram[:-1]\n",
        "        return (self.counts.get(ngram, 0) + self.V) / (self.context_counts.get(context, 0) + self.V)\n",
        "\n",
        "    def prob_sentences(self, tokens, smoothing=\"raw\", k=0.5, log_space=True):\n",
        "      if log_space:\n",
        "          log_prob = 0.0\n",
        "          for i in range(len(tokens) - self.n + 1):\n",
        "              ngram = tuple(tokens[i:i+self.n])\n",
        "              if smoothing == \"raw\":\n",
        "                  p = self.prob(ngram)\n",
        "              elif smoothing == \"addone\":\n",
        "                  p = self.prob_addone(ngram)\n",
        "              elif smoothing == \"addk\":\n",
        "                  p = self.prob_addk(ngram, k)\n",
        "              else:\n",
        "                  p = self.prob_addtokentype(ngram)\n",
        "              if p > 0:\n",
        "                  log_prob += math.log(p)\n",
        "              else:\n",
        "                  log_prob += float('-inf')\n",
        "          return log_prob\n",
        "      else:\n",
        "          prob = 1.0\n",
        "          for i in range(len(tokens) - self.n + 1):\n",
        "              ngram = tuple(tokens[i:i+self.n])\n",
        "              if smoothing == \"raw\":\n",
        "                  prob *= self.prob(ngram)\n",
        "              elif smoothing == \"addone\":\n",
        "                  prob *= self.prob_addone(ngram)\n",
        "              elif smoothing == \"addk\":\n",
        "                  prob *= self.prob_addk(ngram, k)\n",
        "              else:\n",
        "                  prob *= self.prob_addtokentype(ngram)\n",
        "          return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fnGcxtXo75n",
        "outputId": "d3e5017d-5dff-44a4-8e82-a1c454202e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting unigrams...\n",
            "Counting bigrams...\n",
            "Counting trigrams...\n",
            "Counting quadgrams...\n"
          ]
        }
      ],
      "source": [
        "print(\"Counting unigrams...\")\n",
        "uni_counts, uni_context, vocab = count_ngrams_stream(dataset, 1)\n",
        "unigram = Ngram(uni_counts, {}, vocab, 1)\n",
        "\n",
        "print(\"Counting bigrams...\")\n",
        "bi_counts, bi_context, _ = count_ngrams_stream(dataset, 2)\n",
        "bigram = Ngram(bi_counts, uni_counts, vocab, 2)\n",
        "\n",
        "print(\"Counting trigrams...\")\n",
        "tri_counts, tri_context, _ = count_ngrams_stream(dataset, 3)\n",
        "trigram = Ngram(tri_counts, bi_counts, vocab, 3)\n",
        "\n",
        "print(\"Counting quadgrams...\")\n",
        "quad_counts, quad_context, _ = count_ngrams_stream(dataset, 4)\n",
        "quadgram = Ngram(quad_counts, tri_counts, vocab, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfL8sHbam6nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e8e53b-dca8-43c8-a7c8-5112db65c778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 2329\n",
            "Validation size: 1000\n",
            "Test size: 1000\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/telugu-nlp/telugu_news/test_telugu_news.csv\")\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "val_df = df.iloc[:1000]\n",
        "test_df = df.iloc[1000:2000]\n",
        "train_df = df.iloc[2000:]\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Validation size:\", len(val_df))\n",
        "print(\"Test size:\", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR73iBWbj7fA"
      },
      "outputs": [],
      "source": [
        "for sentence in test_df['body'][:10]:\n",
        "    tokens = [\"<bos>\", *telugu_word_tokenizer(sentence), \"<eos>\"]\n",
        "    print(\"Sentence:\", sentence[:60], \"...\")\n",
        "    print(\"Unigram raw:\", unigram.prob_sentences(tokens))\n",
        "    tokens = [\"<bos>\", *telugu_word_tokenizer(sentence), \"<eos>\"]\n",
        "    print(\"Bigram add-one:\", bigram.prob_sentences(tokens, \"addone\"))\n",
        "    tokens = [\"<bos>\" * 2 , *telugu_word_tokenizer(sentence), \"<eos>\"]\n",
        "    print(\"Trigram add-k:\", trigram.prob_sentences(tokens, \"addk\", k=0.5))\n",
        "    tokens = [\"<bos>\" * 3, *telugu_word_tokenizer(sentence), \"<eos>\"]\n",
        "    print(\"Quadgram token-type:\", quadgram.prob_sentences(tokens, \"addtokentype\"))\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTG8yZ7yr6mG"
      },
      "outputs": [],
      "source": [
        "class Ngram:\n",
        "    def __init__(self, counts, context_counts, vocab, n):\n",
        "        self.counts = counts\n",
        "        self.context_counts = context_counts\n",
        "        self.vocab = vocab\n",
        "        self.V = len(vocab)\n",
        "        self.n = n\n",
        "        self.Nc = defaultdict(int)\n",
        "        for c in counts.values():\n",
        "            self.Nc[c] += 1\n",
        "\n",
        "        self.N = sum(counts.values())\n",
        "\n",
        "        self.top100={}\n",
        "\n",
        "    def prob_good_turing(self, ngram):\n",
        "        C = self.counts.get(ngram, 0)\n",
        "        Nc = self.Nc.get(C, 0)\n",
        "        Nc1 = self.Nc.get(C+1, 0)\n",
        "\n",
        "        if C == 0:\n",
        "            N1 = self.Nc.get(1, 0)\n",
        "            return N1 / (self.N * ((self.V ** self.n) - self.N)) if self.N > 0 else 0.0\n",
        "\n",
        "        if Nc == 0:\n",
        "            return C / self.N\n",
        "\n",
        "        C_star = (C+1) * (Nc1 / Nc)\n",
        "\n",
        "        self.top100[C]=[Nc,C_star]\n",
        "\n",
        "        return C_star / self.N\n",
        "\n",
        "    def prob_sentences(self, tokens, use_log=True):\n",
        "        log_prob = 0.0\n",
        "        prob = 1.0\n",
        "\n",
        "        for i in range(len(tokens) - self.n + 1):\n",
        "            ngram = tuple(tokens[i:i+self.n])\n",
        "            p = self.prob_good_turing(ngram)\n",
        "\n",
        "            if use_log:\n",
        "                if p > 0:\n",
        "                    log_prob += math.log(p)\n",
        "                else:\n",
        "                    log_prob += float(\"-inf\")\n",
        "            else:\n",
        "                prob *= p\n",
        "\n",
        "        return log_prob if use_log else prob\n",
        "\n",
        "    def print_top100(self):\n",
        "      rows = []\n",
        "      for C, Nc in self.Nc.items():\n",
        "          Nc1 = self.Nc.get(C+1, 0)\n",
        "          if C == 0:\n",
        "              continue\n",
        "          C_star = (C+1) * (Nc1 / Nc) if Nc > 0 else C\n",
        "          rows.append((C, Nc, round(C_star,3)))\n",
        "\n",
        "      rows = sorted(rows, key=lambda x: x[0], reverse=True)[:100]\n",
        "      print(\"C (MLE)   Nc   C*\")\n",
        "      for C, Nc, C_star in rows:\n",
        "          print(f\"{C:<8} {Nc:<4} {C_star}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7gEItqG1S1T",
        "outputId": "966422fb-2fbd-4371-ceba-cc08ed6b8e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting unigrams...\n",
            "Counting bigrams...\n",
            "Counting trigrams...\n",
            "Counting quadgrams...\n"
          ]
        }
      ],
      "source": [
        "print(\"Counting unigrams...\")\n",
        "uni_counts, uni_context, vocab = count_ngrams_stream(dataset, 1)\n",
        "uni_counts = uni_counts[1]\n",
        "unigram = Ngram(uni_counts, {}, vocab, 1)\n",
        "\n",
        "print(\"Counting bigrams...\")\n",
        "bi_counts, bi_context, _ = count_ngrams_stream(dataset, 2)\n",
        "bi_counts = bi_counts[1]\n",
        "bigram = Ngram(bi_counts, uni_counts, vocab, 2)\n",
        "\n",
        "print(\"Counting trigrams...\")\n",
        "tri_counts, tri_context, _ = count_ngrams_stream(dataset, 3)\n",
        "tri_counts = tri_counts[1]\n",
        "trigram = Ngram(tri_counts, bi_counts, vocab, 3)\n",
        "\n",
        "print(\"Counting quadgrams...\")\n",
        "quad_counts, quad_context, _ = count_ngrams_stream(dataset, 4)\n",
        "quad_counts = quad_counts[1]\n",
        "quadgram = Ngram(quad_counts, tri_counts, vocab, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyb_1oUpx2FY",
        "outputId": "46cd7e62-42fc-4165-d1fb-69e52caf0e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: కరాచీ: చాంపియన్స్ ట్రోఫీలో భారత్‌ను ఓడించే సత్తా పాకిస్థాన్‌ ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -inf\n",
            "Quadgram token-type: -5832.666522225466\n",
            "============================================================\n",
            "Sentence: చాలా ప్రతిష్టాత్మకంగా తెరకెక్కనున్న చిరంజీవి 151వ చిత్రం సై. ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -inf\n",
            "Quadgram token-type: -5763.490267141461\n",
            "============================================================\n",
            "Sentence: అమెరికా కొత్త అధ్యక్షుడు ట్రంప్‌కు చెందిన దుబాయిలోని గోల్ఫ్‌ ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -5971.641103469907\n",
            "Quadgram token-type: -8454.942746253628\n",
            "============================================================\n",
            "Sentence: రాహుల్‌కు ఇద్దరు విదేశీ గర్ల్‌ఫ్రెండ్స్‌.. పెళ్లిపై వేదాంత ధ ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -inf\n",
            "Quadgram token-type: -16346.462049199172\n",
            "============================================================\n",
            "Sentence: \n",
            "నీరజ్‌ శ్యామ్‌, నైరా షా జంటగా నటించిన చిత్రం ‘ఇ.ఈ’. రామ్‌ గ ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -inf\n",
            "Quadgram token-type: -4194.908117069552\n",
            "============================================================\n",
            "Sentence: చండీగఢ్: అత్యాచారం కేసుల్లో కారాగార శిక్ష అనుభవిస్తున్న డేరా ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -inf\n",
            "Quadgram token-type: -6885.491022172782\n",
            "============================================================\n",
            "Sentence: కొందరికీ అన్నీ ఉన్నా సక్సెస్‌లు రావడం కష్టమవుతోంది. మెగా కాం ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -4510.7057192717775\n",
            "Quadgram token-type: -6304.042227211607\n",
            "============================================================\n",
            "Sentence: ప్రసాద్‌కు ద్రోణాచార్య, హకీమ్‌కు ధ్యాన్‌చంద్‌ సాకేత్‌, జ్యోత ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -7703.795721166597\n",
            "Quadgram token-type: -10929.63189680458\n",
            "============================================================\n",
            "Sentence: \n",
            "రహానె అవుట్‌.. ధవన్‌ ఇన్‌ఆసీస్‌తో టీ20లకు భారత జట్టున్యూఢిల ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -8247.77222660845\n",
            "Quadgram token-type: -12503.698296084603\n",
            "============================================================\n",
            "Sentence: లక్నో: హిందువుల మనోభావాలను గుర్తిస్తూ ఉత్తరప్రదేశ్‌లోని షియా ...\n",
            "Unigram raw: -inf\n",
            "Bigram add-one: -inf\n",
            "Trigram add-k: -inf\n",
            "Quadgram token-type: -1885.9005000651402\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "for sentence in test_df['body'][:10]:\n",
        "    tokens = [\"<bos>\", *telugu_word_tokenizer(sentence), \"<eos>\"]\n",
        "    print(\"Sentence:\", sentence[:60], \"...\")\n",
        "    print(\"Unigram raw:\", unigram.prob_sentences(tokens))\n",
        "    print(\"Bigram add-one:\", bigram.prob_sentences(tokens))\n",
        "    print(\"Trigram add-k:\", trigram.prob_sentences(tokens))\n",
        "    print(\"Quadgram token-type:\", quadgram.prob_sentences(tokens))\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfoqv39ly_yd",
        "outputId": "53ef4f45-d029-44bc-bb4f-758c9f8e51a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 100 frequencies of unigram\n",
            "C (MLE)   Nc   C*\n",
            "722767   1    0.0\n",
            "348303   1    0.0\n",
            "107152   1    0.0\n",
            "70566    1    0.0\n",
            "48747    1    0.0\n",
            "36937    1    0.0\n",
            "34873    1    0.0\n",
            "33380    1    0.0\n",
            "29231    1    0.0\n",
            "29052    1    0.0\n",
            "28639    1    0.0\n",
            "28305    1    0.0\n",
            "27982    1    0.0\n",
            "26522    1    0.0\n",
            "25353    1    0.0\n",
            "24409    1    0.0\n",
            "22876    1    0.0\n",
            "22805    1    0.0\n",
            "22683    1    0.0\n",
            "22352    1    0.0\n",
            "21720    1    0.0\n",
            "20583    1    0.0\n",
            "20352    1    0.0\n",
            "20097    1    0.0\n",
            "19662    1    0.0\n",
            "18792    1    0.0\n",
            "18457    1    0.0\n",
            "17942    1    0.0\n",
            "17603    1    0.0\n",
            "17507    1    0.0\n",
            "16760    1    0.0\n",
            "16341    1    0.0\n",
            "15577    1    0.0\n",
            "15483    1    0.0\n",
            "15434    1    0.0\n",
            "15101    1    0.0\n",
            "14567    1    0.0\n",
            "14246    1    0.0\n",
            "13917    1    0.0\n",
            "13718    1    0.0\n",
            "13709    1    0.0\n",
            "13554    1    0.0\n",
            "13305    1    0.0\n",
            "13182    1    0.0\n",
            "12956    1    0.0\n",
            "12547    1    0.0\n",
            "12363    1    0.0\n",
            "11838    1    0.0\n",
            "11649    1    0.0\n",
            "11551    1    0.0\n",
            "11547    1    0.0\n",
            "11310    1    0.0\n",
            "11243    1    0.0\n",
            "11026    1    0.0\n",
            "10777    1    0.0\n",
            "10715    1    0.0\n",
            "10693    1    0.0\n",
            "10650    1    0.0\n",
            "10629    1    0.0\n",
            "10584    1    0.0\n",
            "10487    1    0.0\n",
            "10453    1    0.0\n",
            "10381    1    0.0\n",
            "10356    1    0.0\n",
            "10285    1    0.0\n",
            "10230    1    0.0\n",
            "10204    1    0.0\n",
            "10175    1    0.0\n",
            "10051    1    0.0\n",
            "9829     1    0.0\n",
            "9809     1    0.0\n",
            "9702     1    0.0\n",
            "9673     1    0.0\n",
            "9592     1    0.0\n",
            "9528     1    0.0\n",
            "9521     1    0.0\n",
            "9466     1    0.0\n",
            "9241     1    0.0\n",
            "9121     1    0.0\n",
            "9110     1    0.0\n",
            "8786     1    0.0\n",
            "8781     1    0.0\n",
            "8774     1    0.0\n",
            "8736     1    0.0\n",
            "8710     1    0.0\n",
            "8657     1    0.0\n",
            "8601     1    0.0\n",
            "8594     1    0.0\n",
            "8538     1    0.0\n",
            "8532     2    0.0\n",
            "8502     1    0.0\n",
            "8433     1    0.0\n",
            "8277     1    0.0\n",
            "8253     1    0.0\n",
            "8081     1    0.0\n",
            "8048     1    0.0\n",
            "7908     1    0.0\n",
            "7873     1    0.0\n",
            "7734     1    0.0\n",
            "7624     1    0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"top 100 frequencies of unigram\")\n",
        "unigram.print_top100()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exEwDbUQ0KFa",
        "outputId": "88dfa90e-be52-4bcd-9896-00ced7a1df63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 100 frequencies of bigram\n",
            "C (MLE)   Nc   C*\n",
            "722760   1    0.0\n",
            "70558    1    0.0\n",
            "47934    1    0.0\n",
            "23415    1    0.0\n",
            "20136    1    0.0\n",
            "17658    1    0.0\n",
            "17340    1    0.0\n",
            "15482    1    0.0\n",
            "15434    1    0.0\n",
            "13200    1    0.0\n",
            "11193    1    0.0\n",
            "9800     1    0.0\n",
            "9785     1    0.0\n",
            "9741     1    0.0\n",
            "9415     1    0.0\n",
            "8588     1    0.0\n",
            "8384     1    0.0\n",
            "8258     1    0.0\n",
            "8231     1    0.0\n",
            "8105     1    0.0\n",
            "7988     1    0.0\n",
            "7921     1    0.0\n",
            "7686     1    0.0\n",
            "7294     1    0.0\n",
            "7263     1    0.0\n",
            "6544     1    0.0\n",
            "6415     1    0.0\n",
            "6007     1    0.0\n",
            "5923     1    0.0\n",
            "5672     1    0.0\n",
            "5481     1    0.0\n",
            "4985     1    0.0\n",
            "4906     1    0.0\n",
            "4535     1    0.0\n",
            "4411     1    0.0\n",
            "4230     1    0.0\n",
            "4083     1    0.0\n",
            "4037     1    0.0\n",
            "4000     1    0.0\n",
            "3992     1    0.0\n",
            "3912     1    0.0\n",
            "3799     1    0.0\n",
            "3797     1    0.0\n",
            "3770     1    0.0\n",
            "3725     1    0.0\n",
            "3655     1    0.0\n",
            "3607     1    0.0\n",
            "3577     1    0.0\n",
            "3575     1    0.0\n",
            "3536     1    0.0\n",
            "3522     1    0.0\n",
            "3512     1    0.0\n",
            "3485     1    0.0\n",
            "3451     1    0.0\n",
            "3424     1    0.0\n",
            "3422     1    0.0\n",
            "3421     1    3422.0\n",
            "3411     2    0.0\n",
            "3340     1    0.0\n",
            "3331     1    0.0\n",
            "3262     1    0.0\n",
            "3225     1    0.0\n",
            "3224     1    3225.0\n",
            "3204     1    0.0\n",
            "3192     1    0.0\n",
            "3174     1    0.0\n",
            "3150     1    0.0\n",
            "3102     1    0.0\n",
            "2997     1    0.0\n",
            "2991     1    0.0\n",
            "2942     1    0.0\n",
            "2925     1    0.0\n",
            "2869     1    0.0\n",
            "2862     1    0.0\n",
            "2819     1    0.0\n",
            "2749     1    0.0\n",
            "2717     1    0.0\n",
            "2644     1    0.0\n",
            "2604     1    0.0\n",
            "2593     1    0.0\n",
            "2567     1    0.0\n",
            "2565     1    0.0\n",
            "2527     1    0.0\n",
            "2507     1    0.0\n",
            "2469     1    0.0\n",
            "2432     1    0.0\n",
            "2417     1    0.0\n",
            "2413     1    0.0\n",
            "2403     1    0.0\n",
            "2383     1    0.0\n",
            "2371     1    0.0\n",
            "2348     1    0.0\n",
            "2322     1    0.0\n",
            "2247     1    0.0\n",
            "2206     1    0.0\n",
            "2199     1    0.0\n",
            "2189     1    0.0\n",
            "2158     1    0.0\n",
            "2137     1    0.0\n",
            "2083     1    0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"top 100 frequencies of bigram\")\n",
        "bigram.print_top100()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt9CUbJ-0WF6",
        "outputId": "00fa30b0-0383-4044-c5c9-a7989718fb98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 100 frequencies of trigram\n",
            "C (MLE)   Nc   C*\n",
            "722760   1    0.0\n",
            "70558    1    0.0\n",
            "47934    1    0.0\n",
            "23415    1    0.0\n",
            "20136    1    0.0\n",
            "17658    1    0.0\n",
            "17340    1    0.0\n",
            "15482    1    0.0\n",
            "15434    1    0.0\n",
            "13200    1    0.0\n",
            "11193    1    0.0\n",
            "9800     1    0.0\n",
            "9785     1    0.0\n",
            "9741     1    0.0\n",
            "9415     1    0.0\n",
            "8588     1    0.0\n",
            "8384     1    0.0\n",
            "8258     1    0.0\n",
            "8230     1    0.0\n",
            "7881     1    0.0\n",
            "7686     1    0.0\n",
            "7294     1    0.0\n",
            "7263     1    0.0\n",
            "6544     1    0.0\n",
            "6415     1    0.0\n",
            "6007     1    0.0\n",
            "5923     1    0.0\n",
            "5577     1    0.0\n",
            "5481     1    0.0\n",
            "4985     1    0.0\n",
            "4906     1    0.0\n",
            "4577     1    0.0\n",
            "4371     1    0.0\n",
            "4232     1    0.0\n",
            "4230     1    0.0\n",
            "4083     1    0.0\n",
            "4037     1    0.0\n",
            "4000     1    0.0\n",
            "3992     1    0.0\n",
            "3912     1    0.0\n",
            "3799     1    0.0\n",
            "3797     1    0.0\n",
            "3770     1    0.0\n",
            "3725     1    0.0\n",
            "3575     1    0.0\n",
            "3536     1    0.0\n",
            "3515     1    0.0\n",
            "3512     1    0.0\n",
            "3451     1    0.0\n",
            "3422     1    0.0\n",
            "3421     1    3422.0\n",
            "3420     1    3421.0\n",
            "3411     1    0.0\n",
            "3340     1    0.0\n",
            "3331     1    0.0\n",
            "3234     1    0.0\n",
            "3225     1    0.0\n",
            "3204     1    0.0\n",
            "3192     1    0.0\n",
            "3178     1    0.0\n",
            "3150     1    0.0\n",
            "3102     1    0.0\n",
            "2997     1    0.0\n",
            "2991     1    0.0\n",
            "2942     1    0.0\n",
            "2925     1    0.0\n",
            "2911     1    0.0\n",
            "2882     1    0.0\n",
            "2869     1    0.0\n",
            "2862     1    0.0\n",
            "2819     1    0.0\n",
            "2749     1    0.0\n",
            "2717     1    0.0\n",
            "2593     1    0.0\n",
            "2565     1    0.0\n",
            "2527     1    0.0\n",
            "2469     1    0.0\n",
            "2432     1    0.0\n",
            "2417     1    0.0\n",
            "2413     1    0.0\n",
            "2371     1    0.0\n",
            "2348     1    0.0\n",
            "2300     1    0.0\n",
            "2284     1    0.0\n",
            "2225     1    0.0\n",
            "2206     1    0.0\n",
            "2199     1    0.0\n",
            "2189     1    0.0\n",
            "2166     1    0.0\n",
            "2158     1    0.0\n",
            "2088     1    0.0\n",
            "2083     1    0.0\n",
            "2029     1    0.0\n",
            "2026     1    0.0\n",
            "2011     1    0.0\n",
            "1922     1    0.0\n",
            "1899     1    0.0\n",
            "1886     1    0.0\n",
            "1873     1    0.0\n",
            "1871     1    0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"top 100 frequencies of trigram\")\n",
        "trigram.print_top100()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taHCBTh60YdR",
        "outputId": "8948fc59-8d0e-4e84-dc6d-d359fd29c5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 100 frequencies of quadgram\n",
            "C (MLE)   Nc   C*\n",
            "722760   1    0.0\n",
            "70558    1    0.0\n",
            "47934    1    0.0\n",
            "23415    1    0.0\n",
            "20136    1    0.0\n",
            "17658    1    0.0\n",
            "17340    1    0.0\n",
            "15482    1    0.0\n",
            "15434    1    0.0\n",
            "13200    1    0.0\n",
            "11193    1    0.0\n",
            "9800     1    0.0\n",
            "9785     1    0.0\n",
            "9741     1    0.0\n",
            "9415     1    0.0\n",
            "8588     1    0.0\n",
            "8384     1    0.0\n",
            "8258     1    0.0\n",
            "8230     1    0.0\n",
            "7686     1    0.0\n",
            "7294     1    0.0\n",
            "7263     1    0.0\n",
            "6544     1    0.0\n",
            "6415     1    0.0\n",
            "6007     1    0.0\n",
            "5923     1    0.0\n",
            "5577     1    0.0\n",
            "5481     1    0.0\n",
            "4985     1    0.0\n",
            "4906     1    0.0\n",
            "4577     1    0.0\n",
            "4371     1    0.0\n",
            "4351     1    0.0\n",
            "4232     1    0.0\n",
            "4230     1    0.0\n",
            "4083     1    0.0\n",
            "4037     1    0.0\n",
            "4000     1    0.0\n",
            "3992     1    0.0\n",
            "3912     1    0.0\n",
            "3799     1    0.0\n",
            "3797     1    0.0\n",
            "3770     1    0.0\n",
            "3725     1    0.0\n",
            "3575     1    0.0\n",
            "3536     1    0.0\n",
            "3512     1    0.0\n",
            "3451     1    0.0\n",
            "3422     1    0.0\n",
            "3420     2    0.0\n",
            "3411     1    0.0\n",
            "3340     1    0.0\n",
            "3331     1    0.0\n",
            "3229     1    0.0\n",
            "3225     1    0.0\n",
            "3204     1    0.0\n",
            "3192     1    0.0\n",
            "3178     1    0.0\n",
            "3150     1    0.0\n",
            "3102     1    0.0\n",
            "2997     1    0.0\n",
            "2991     1    0.0\n",
            "2942     1    0.0\n",
            "2925     1    0.0\n",
            "2911     1    0.0\n",
            "2882     1    0.0\n",
            "2869     1    0.0\n",
            "2862     1    0.0\n",
            "2819     1    0.0\n",
            "2749     1    0.0\n",
            "2717     1    0.0\n",
            "2593     1    0.0\n",
            "2565     1    0.0\n",
            "2527     1    0.0\n",
            "2469     1    0.0\n",
            "2432     1    0.0\n",
            "2417     1    0.0\n",
            "2413     1    0.0\n",
            "2371     1    0.0\n",
            "2348     1    0.0\n",
            "2300     1    0.0\n",
            "2284     1    0.0\n",
            "2225     2    0.0\n",
            "2206     1    0.0\n",
            "2199     1    0.0\n",
            "2189     1    0.0\n",
            "2166     1    0.0\n",
            "2158     1    0.0\n",
            "2088     1    0.0\n",
            "2083     1    0.0\n",
            "2029     1    0.0\n",
            "2026     1    0.0\n",
            "2011     1    0.0\n",
            "1977     1    0.0\n",
            "1922     1    0.0\n",
            "1899     1    0.0\n",
            "1886     1    0.0\n",
            "1873     1    0.0\n",
            "1871     1    0.0\n",
            "1847     1    0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"top 100 frequencies of quadgram\")\n",
        "quadgram.print_top100()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fI3uAzW1uGF"
      },
      "outputs": [],
      "source": [
        "lam={'l1':0,'l2':0,'l3':0,'l4':0}\n",
        "for example in islice(dataset, 500000):\n",
        "        text = example.get(\"text\") or example.get(\"content\") or \"\"\n",
        "        if not text.strip():\n",
        "            continue\n",
        "        for sentence in telugu_sentence_tokenizer(text):\n",
        "          tokens = [\"<bos>\", *telugu_word_tokenizer(sentence), \"<eos>\"]\n",
        "          lam['l1']+=unigram.prob_sentences(tokens,use_log=True)\n",
        "          lam['l2']+=bigram.prob_sentences(tokens,use_log=True)\n",
        "          lam['l3']+=trigram.prob_sentences(tokens,use_log=True)\n",
        "          lam['l4']+=quadgram.prob_sentences(tokens,use_log=True)\n",
        "\n",
        "sum=lam['l1']+lam['l2']+lam['l3']+lam['l4']\n",
        "lam['l1']=lam['l1']/sum\n",
        "lam['l2']=lam['l2']/sum\n",
        "lam['l3']=lam['l3']/sum\n",
        "lam['l4']=lam['l4']/sum\n",
        "\n",
        "# def deleted_interpolation(lam,n,tokens):\n",
        "  # return (lam['l1'] if n>=1 else 0)*unigram.prob_sentences(tokens)+ (lam['l2'] if n>=2 else 0)*bigram.prob_sentences(tokens)+ (lam['l3'] if n>=3 else 0)*trigram.prob_sentences(tokens)+ (lam['l4'] if n>=4 else 0)*quadgram.prob_sentences(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyvtQ_LAAHys",
        "outputId": "831c4e6f-1ea2-4594-ad6d-fb04cdc7d3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'l1': nan, 'l2': nan, 'l3': nan, 'l4': nan}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deleted_interpolation(tokens, lam, models, n):\n",
        "    score = 0.0\n",
        "    for order in range(1, n+1):\n",
        "        score += lam[f\"l{order}\"] * models[order].prob_sentences(tokens)\n",
        "    return score"
      ],
      "metadata": {
        "id": "ECvPZttQ6qCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XrnfOpwAuTO",
        "outputId": "21da6038-94ba-42be-b03e-838c7be23866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: కరాచీ: చాంపియన్స్ ట్రోఫీలో భారత్‌ను ఓడించే సత్తా పాకిస్థాన్‌ ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: చాలా ప్రతిష్టాత్మకంగా తెరకెక్కనున్న చిరంజీవి 151వ చిత్రం సై. ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: అమెరికా కొత్త అధ్యక్షుడు ట్రంప్‌కు చెందిన దుబాయిలోని గోల్ఫ్‌ ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: రాహుల్‌కు ఇద్దరు విదేశీ గర్ల్‌ఫ్రెండ్స్‌.. పెళ్లిపై వేదాంత ధ ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: \n",
            "నీరజ్‌ శ్యామ్‌, నైరా షా జంటగా నటించిన చిత్రం ‘ఇ.ఈ’. రామ్‌ గ ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: చండీగఢ్: అత్యాచారం కేసుల్లో కారాగార శిక్ష అనుభవిస్తున్న డేరా ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: కొందరికీ అన్నీ ఉన్నా సక్సెస్‌లు రావడం కష్టమవుతోంది. మెగా కాం ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: ప్రసాద్‌కు ద్రోణాచార్య, హకీమ్‌కు ధ్యాన్‌చంద్‌ సాకేత్‌, జ్యోత ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: \n",
            "రహానె అవుట్‌.. ధవన్‌ ఇన్‌ఆసీస్‌తో టీ20లకు భారత జట్టున్యూఢిల ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n",
            "Sentence: లక్నో: హిందువుల మనోభావాలను గుర్తిస్తూ ఉత్తరప్రదేశ్‌లోని షియా ...\n",
            "Deleted interpolation (n=4): nan\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "models = {1: unigram, 2: bigram, 3: trigram, 4: quadgram}\n",
        "\n",
        "for sentence in test_df['body'][:10]:\n",
        "    tokens = [\"<bos>\", *telugu_word_tokenizer(sentence), \"<eos>\"]\n",
        "    print(\"Sentence:\", sentence[:60], \"...\")\n",
        "    print(\"Deleted interpolation (n=4):\", deleted_interpolation(tokens, lam, models, 4))\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KatzNgram:\n",
        "  def __init__(self,n,counts,context_counts,lower_order_model,k=5):\n",
        "    self.n=n\n",
        "    self.k=k\n",
        "    self.counts=counts\n",
        "    self.context_counts=context_counts\n",
        "    self.lower_order_model=lower_order_model\n",
        "\n",
        "    self.N=sum(self.counts.values())\n",
        "    self.Nc=defaultdict(int)\n",
        "    for c in self.counts.values():\n",
        "      if c<=self.k+1:\n",
        "       self.Nc[c]+=1\n",
        "\n",
        "    self._calculate_discounts()\n",
        "    if self.lower_order_model:\n",
        "      self._calculate_alphas()\n",
        "\n",
        "  def _get_discounts(self,count):\n",
        "    if count==0:\n",
        "      return 1.0\n",
        "\n",
        "    if count>self.k:\n",
        "      return 1.0\n",
        "\n",
        "    Nc=self.Nc.get(count,0)\n",
        "    Nc1=self.Nc.get(count+1,0)\n",
        "\n",
        "    if Nc==0 or Nc1==0:\n",
        "      return 1.0\n",
        "\n",
        "    C_star = (count+1)*(Nc1/Nc)\n",
        "    return C_star/count\n",
        "\n",
        "  def _calculate_discounts(self):\n",
        "    self.discounts={c:self._get_discounts(c) for c in range(1,self.k+1)}\n",
        "\n",
        "  def _calculate_alphas(self):\n",
        "    self.alphas={}\n",
        "    context_groups=defaultdict(list)\n",
        "    for ngram in self.counts.keys():\n",
        "      context_groups[ngram[:-1]].append(ngram)\n",
        "\n",
        "    for context, context_count in self.context_counts.items():\n",
        "            prob_mass_seen = 0.0\n",
        "            for ngram in context_groups[context]:\n",
        "                count = self.counts.get(ngram, 0)\n",
        "                discount = self.discounts.get(count, 1.0)\n",
        "                prob_mass_seen += (count * discount) / context_count\n",
        "\n",
        "            lower_order_prob_mass = 0.0\n",
        "            for ngram in context_groups[context]:\n",
        "                lower_order_prob_mass += self.lower_order_model.prob(ngram[1:])\n",
        "\n",
        "            numerator = 1.0 - prob_mass_seen\n",
        "            denominator = 1.0 - lower_order_prob_mass\n",
        "\n",
        "            if denominator == 0:\n",
        "                self.alphas[context] = 1.0\n",
        "            else:\n",
        "                self.alphas[context] = numerator / denominator\n",
        "\n",
        "  def prob(self, ngram):\n",
        "        if self.n == 1:\n",
        "            count = self.counts.get(ngram, 0)\n",
        "\n",
        "            if count == 0:\n",
        "                N1 = self.Nc.get(1, 0)\n",
        "                return N1 / self.N if self.N > 0 else 0\n",
        "\n",
        "            return count / self.N\n",
        "\n",
        "        count = self.counts.get(ngram, 0)\n",
        "        context = ngram[:-1]\n",
        "        context_count = self.context_counts.get(context, 0)\n",
        "\n",
        "        if count > 0:\n",
        "            discount = self.discounts.get(count, 1.0)\n",
        "            if context_count == 0:\n",
        "               return 0.0\n",
        "            return (count * discount) / context_count\n",
        "\n",
        "        else:\n",
        "            alpha = self.alphas.get(context, 1.0)\n",
        "            return alpha * self.lower_order_model.prob(ngram[1:])\n",
        "\n",
        "  def sentence_log_prob(self, tokens):\n",
        "        log_prob = 0.0\n",
        "        for i in range(len(tokens) - self.n + 1):\n",
        "            ngram = tuple(tokens[i:i+self.n])\n",
        "            p = self.prob(ngram)\n",
        "            if p > 0:\n",
        "                log_prob += math.log(p)\n",
        "            else:\n",
        "                return float('-inf')\n",
        "        return log_prob"
      ],
      "metadata": {
        "id": "wlypM8HS7K3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_katz = KatzNgram(1, uni_counts, {}, lower_order_model=None)\n",
        "bigram_katz = KatzNgram(2, bi_counts, uni_counts, lower_order_model=unigram_katz)\n",
        "trigram_katz = KatzNgram(3, tri_counts, bi_counts, lower_order_model=bigram_katz)\n",
        "quadgram_katz = KatzNgram(4, quad_counts, tri_counts, lower_order_model=trigram_katz)\n",
        "print(\"Models built.\")\n",
        "\n",
        "for sentence in test_df['body'][:10]:\n",
        "    print(\"Sentence:\", sentence[:60], \"...\")\n",
        "    tokens_uni = telugu_word_tokenizer(sentence) + [\"<eos>\"]\n",
        "\n",
        "    tokens_bi = [\"<bos>\"] + telugu_word_tokenizer(sentence) + [\"<eos>\"]\n",
        "\n",
        "    tokens_tri = [\"<bos>\"] * 2 + telugu_word_tokenizer(sentence) + [\"<eos>\"]\n",
        "\n",
        "    tokens_quad = [\"<bos>\"] * 3 + telugu_word_tokenizer(sentence) + [\"<eos>\"]\n",
        "\n",
        "    print(f\"Unigram Log Prob: {unigram_katz.sentence_log_prob(tokens_uni):.2f}\")\n",
        "    print(f\"Bigram Log Prob:  {bigram_katz.sentence_log_prob(tokens_bi):.2f}\")\n",
        "    print(f\"Trigram Log Prob: {trigram_katz.sentence_log_prob(tokens_tri):.2f}\")\n",
        "    print(f\"Quadgram Log Prob:{quadgram_katz.sentence_log_prob(tokens_quad):.2f}\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGAaJLDy-bs8",
        "outputId": "ea7270b1-9b17-4e82-c0e4-929d29e99b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models built.\n",
            "Sentence: కరాచీ: చాంపియన్స్ ట్రోఫీలో భారత్‌ను ఓడించే సత్తా పాకిస్థాన్‌ ...\n",
            "Unigram Log Prob: -1007.72\n",
            "Bigram Log Prob:  -1007.72\n",
            "Trigram Log Prob: -1007.72\n",
            "Quadgram Log Prob:-1007.72\n",
            "============================================================\n",
            "Sentence: చాలా ప్రతిష్టాత్మకంగా తెరకెక్కనున్న చిరంజీవి 151వ చిత్రం సై. ...\n",
            "Unigram Log Prob: -974.14\n",
            "Bigram Log Prob:  -974.14\n",
            "Trigram Log Prob: -974.14\n",
            "Quadgram Log Prob:-974.14\n",
            "============================================================\n",
            "Sentence: అమెరికా కొత్త అధ్యక్షుడు ట్రంప్‌కు చెందిన దుబాయిలోని గోల్ఫ్‌ ...\n",
            "Unigram Log Prob: -1448.16\n",
            "Bigram Log Prob:  -1448.16\n",
            "Trigram Log Prob: -1448.16\n",
            "Quadgram Log Prob:-1448.16\n",
            "============================================================\n",
            "Sentence: రాహుల్‌కు ఇద్దరు విదేశీ గర్ల్‌ఫ్రెండ్స్‌.. పెళ్లిపై వేదాంత ధ ...\n",
            "Unigram Log Prob: -2553.84\n",
            "Bigram Log Prob:  -2553.84\n",
            "Trigram Log Prob: -2553.84\n",
            "Quadgram Log Prob:-2553.84\n",
            "============================================================\n",
            "Sentence: \n",
            "నీరజ్‌ శ్యామ్‌, నైరా షా జంటగా నటించిన చిత్రం ‘ఇ.ఈ’. రామ్‌ గ ...\n",
            "Unigram Log Prob: -696.23\n",
            "Bigram Log Prob:  -696.23\n",
            "Trigram Log Prob: -696.23\n",
            "Quadgram Log Prob:-696.23\n",
            "============================================================\n",
            "Sentence: చండీగఢ్: అత్యాచారం కేసుల్లో కారాగార శిక్ష అనుభవిస్తున్న డేరా ...\n",
            "Unigram Log Prob: -1210.18\n",
            "Bigram Log Prob:  -1210.18\n",
            "Trigram Log Prob: -1210.18\n",
            "Quadgram Log Prob:-1210.18\n",
            "============================================================\n",
            "Sentence: కొందరికీ అన్నీ ఉన్నా సక్సెస్‌లు రావడం కష్టమవుతోంది. మెగా కాం ...\n",
            "Unigram Log Prob: -1108.56\n",
            "Bigram Log Prob:  -1108.56\n",
            "Trigram Log Prob: -1108.56\n",
            "Quadgram Log Prob:-1108.56\n",
            "============================================================\n",
            "Sentence: ప్రసాద్‌కు ద్రోణాచార్య, హకీమ్‌కు ధ్యాన్‌చంద్‌ సాకేత్‌, జ్యోత ...\n",
            "Unigram Log Prob: -1936.23\n",
            "Bigram Log Prob:  -1936.23\n",
            "Trigram Log Prob: -1936.23\n",
            "Quadgram Log Prob:-1936.23\n",
            "============================================================\n",
            "Sentence: \n",
            "రహానె అవుట్‌.. ధవన్‌ ఇన్‌ఆసీస్‌తో టీ20లకు భారత జట్టున్యూఢిల ...\n",
            "Unigram Log Prob: -2212.54\n",
            "Bigram Log Prob:  -2212.54\n",
            "Trigram Log Prob: -2212.54\n",
            "Quadgram Log Prob:-2212.54\n",
            "============================================================\n",
            "Sentence: లక్నో: హిందువుల మనోభావాలను గుర్తిస్తూ ఉత్తరప్రదేశ్‌లోని షియా ...\n",
            "Unigram Log Prob: -334.97\n",
            "Bigram Log Prob:  -334.97\n",
            "Trigram Log Prob: -334.97\n",
            "Quadgram Log Prob:-334.97\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KneserNeyNgram:\n",
        "    def __init__(self, n, counts, context_counts, lower_order_model=None, all_ngrams_by_order=None, d=0.75):\n",
        "        self.n = n\n",
        "        self.d = d\n",
        "        self.counts = counts\n",
        "        self.context_counts = context_counts\n",
        "        self.lower_order_model = lower_order_model\n",
        "        self.all_ngrams_by_order = all_ngrams_by_order\n",
        "\n",
        "        if self.n > 1:\n",
        "            self.lambda_numerator_counts = defaultdict(set)\n",
        "            for ngram in self.counts:\n",
        "                context = ngram[:-1]\n",
        "                word = ngram[-1]\n",
        "                self.lambda_numerator_counts[context].add(word)\n",
        "        else:\n",
        "            self.continuation_counts = defaultdict(set)\n",
        "            bigrams = self.all_ngrams_by_order.get(2, set())\n",
        "            for w1, w2 in bigrams:\n",
        "                self.continuation_counts[w2].add(w1)\n",
        "            self.total_bigrams = len(bigrams)\n",
        "\n",
        "    def _get_continuation_prob(self, ngram_tuple):\n",
        "        if self.n == 1:\n",
        "            word = ngram_tuple[0]\n",
        "            numerator = len(self.continuation_counts.get(word, set()))\n",
        "            denominator = self.total_bigrams if self.total_bigrams > 0 else 1\n",
        "            return numerator / denominator\n",
        "        else:\n",
        "            raise NotImplementedError(\"Continuation prob is handled by recursion.\")\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        if self.n == 1:\n",
        "            return self._get_continuation_prob(ngram)\n",
        "\n",
        "        context = ngram[:-1]\n",
        "        context_count = self.context_counts.get(context, 0)\n",
        "\n",
        "        if context_count == 0:\n",
        "            return self.lower_order_model.prob(ngram[1:])\n",
        "\n",
        "        ngram_count = self.counts.get(ngram, 0)\n",
        "        first_term = max(ngram_count - self.d, 0) / context_count\n",
        "\n",
        "        num_unique_following_words = len(self.lambda_numerator_counts.get(context, set()))\n",
        "        lambda_weight = (self.d / context_count) * num_unique_following_words\n",
        "\n",
        "        lower_order_prob = self.lower_order_model.prob(ngram[1:])\n",
        "\n",
        "        return first_term + (lambda_weight * lower_order_prob)\n",
        "\n",
        "    def sentence_log_prob(self, tokens):\n",
        "        log_prob = 0.0\n",
        "        for i in range(len(tokens) - self.n + 1):\n",
        "            ngram = tuple(tokens[i : i + self.n])\n",
        "            p = self.prob(ngram)\n",
        "            if p > 0:\n",
        "                log_prob += math.log(p)\n",
        "            else:\n",
        "                return float('-inf')\n",
        "        return log_prob"
      ],
      "metadata": {
        "id": "7FPD6zI8_pwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_all_ngrams_stream(dataset, max_n, limit=500000):\n",
        "    counts = {n: defaultdict(int) for n in range(1, max_n + 1)}\n",
        "    vocab = set()\n",
        "    dataset = dataset.iter(batch_size=1)\n",
        "\n",
        "    for example in islice(dataset, limit):\n",
        "        raw_text = example.get(\"text\") or example.get(\"content\") or \"\"\n",
        "\n",
        "        if isinstance(raw_text, list):\n",
        "            text = \" \".join(raw_text)\n",
        "        else:\n",
        "            text = raw_text\n",
        "        if not text.strip():\n",
        "            continue\n",
        "\n",
        "        for sentence in telugu_sentence_tokenizer(text):\n",
        "            tokens = ([\"<bos>\"] * (max_n - 1)) + telugu_word_tokenizer(sentence) + [\"<eos>\"]\n",
        "            vocab.update(tokens)\n",
        "            for n in range(1, max_n + 1):\n",
        "                for i in range(len(tokens) - n + 1):\n",
        "                    ngram = tuple(tokens[i:i+n])\n",
        "                    counts[n][ngram] += 1\n",
        "\n",
        "    ngram_counts = {n: dict(counts[n]) for n in range(1, max_n + 1)}\n",
        "    return ngram_counts, vocab"
      ],
      "metadata": {
        "id": "mQNmB6GxHduJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Counting all n-grams in a single pass...\")\n",
        "ngram_counts, vocab = count_all_ngrams_stream(dataset, max_n=4)\n",
        "print(\"Counting complete.\")\n",
        "\n",
        "uni_counts = ngram_counts[1]\n",
        "bi_counts = ngram_counts[2]\n",
        "tri_counts = ngram_counts[3]\n",
        "quad_counts = ngram_counts[4]\n",
        "\n",
        "all_ngrams_by_order = {\n",
        "    1: set(uni_counts.keys()),\n",
        "    2: set(bi_counts.keys()),\n",
        "    3: set(tri_counts.keys()),\n",
        "    4: set(quad_counts.keys())\n",
        "}\n",
        "\n",
        "print(\"Building Kneser-Ney backoff models...\")\n",
        "unigram_kn = KneserNeyNgram(1, uni_counts, {},\n",
        "                            lower_order_model=None,\n",
        "                            all_ngrams_by_order=all_ngrams_by_order)\n",
        "\n",
        "bigram_kn = KneserNeyNgram(2, bi_counts, uni_counts,\n",
        "                           lower_order_model=unigram_kn,\n",
        "                           all_ngrams_by_order=all_ngrams_by_order)\n",
        "\n",
        "trigram_kn = KneserNeyNgram(3, tri_counts, bi_counts,\n",
        "                            lower_order_model=bigram_kn,\n",
        "                            all_ngrams_by_order=all_ngrams_by_order)\n",
        "\n",
        "quadgram_kn = KneserNeyNgram(4, quad_counts, tri_counts,\n",
        "                             lower_order_model=trigram_kn,\n",
        "                             all_ngrams_by_order=all_ngrams_by_order)\n",
        "print(\"Models built successfully.\")\n",
        "\n",
        "for sentence in test_df['body'][:10]:\n",
        "    print(\"Sentence:\", sentence[:60], \"...\")\n",
        "    tokens = [\"<bos>\"] * 3 + telugu_word_tokenizer(sentence) + [\"<eos>\"]\n",
        "    log_probability = quadgram_kn.sentence_log_prob(tokens)\n",
        "    print(f\"Quadgram Kneser-Ney Log Prob: {log_probability:.2f}\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtBhYWF1_-K6",
        "outputId": "966064b3-258a-4439-ee6e-473cb9800d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting all n-grams in a single pass...\n",
            "Counting complete.\n",
            "Building Kneser-Ney backoff models...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "class NgramGenerator:\n",
        "    def __init__(self, unigram, bigram, trigram, quadgram):\n",
        "        self.models = {\n",
        "            1: unigram,\n",
        "            2: bigram,\n",
        "            3: trigram,\n",
        "            4: quadgram\n",
        "        }\n",
        "\n",
        "    def _get_next_word_candidates(self, model, context):\n",
        "        if not isinstance(context, tuple):\n",
        "            context = tuple(context)\n",
        "\n",
        "        candidates = []\n",
        "        if model.n == 1:\n",
        "            for ngram, count in model.counts.items():\n",
        "                log_prob = math.log(model.prob(ngram))\n",
        "                candidates.append((log_prob, ngram[0]))\n",
        "            return candidates\n",
        "\n",
        "        for ngram, count in model.counts.items():\n",
        "            if ngram[:-1] == context:\n",
        "                log_prob = math.log(model.prob(ngram))\n",
        "                candidates.append((log_prob, ngram[-1]))\n",
        "\n",
        "        return sorted(candidates, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    def generate_greedy(self, model_order, max_len=25):\n",
        "        model = self.models[model_order]\n",
        "        n = model.n\n",
        "\n",
        "        sentence = [\"<bos>\"] * (n - 1) if n > 1 else []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            context = tuple(sentence[-(n - 1):]) if n > 1 else tuple()\n",
        "\n",
        "            candidates = self._get_next_word_candidates(model, context)\n",
        "\n",
        "            if not candidates:\n",
        "                break\n",
        "            best_word = candidates[0][1]\n",
        "\n",
        "            if best_word == \"<eos>\":\n",
        "                break\n",
        "\n",
        "            sentence.append(best_word)\n",
        "\n",
        "        return \" \".join(sentence[(n-1):])\n",
        "\n",
        "    def generate_beam(self, model_order, beam_size=20, max_len=30):\n",
        "        model = self.models[model_order]\n",
        "        n = model.n\n",
        "\n",
        "        initial_tokens = [\"<bos>\"] * (n - 1) if n > 1 else []\n",
        "        active_beams = [(0.0, initial_tokens)]\n",
        "        completed_beams = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            new_beams = []\n",
        "            for log_prob, tokens in active_beams:\n",
        "                if tokens[-1] == \"<eos>\":\n",
        "                    completed_beams.append((log_prob, tokens))\n",
        "                    continue\n",
        "\n",
        "                context = tuple(tokens[-(n - 1):]) if n > 1 else tuple()\n",
        "\n",
        "                candidates = self._get_next_word_candidates(model, context)\n",
        "\n",
        "                for cand_log_prob, cand_word in candidates[:beam_size]:\n",
        "                    new_tokens = tokens + [cand_word]\n",
        "                    new_log_prob = log_prob + cand_log_prob\n",
        "                    new_beams.append((new_log_prob, new_tokens))\n",
        "            active_beams = heapq.nlargest(beam_size, new_beams, key=lambda x: x[0])\n",
        "\n",
        "            if not active_beams:\n",
        "                break\n",
        "\n",
        "        all_candidates = completed_beams + active_beams\n",
        "        if not all_candidates:\n",
        "            return \"\"\n",
        "        best_log_prob, best_sentence = max(all_candidates, key=lambda x: x[0])\n",
        "        start_index = (n-1) if n > 1 else 0\n",
        "        if best_sentence[-1] == \"<eos>\":\n",
        "            best_sentence = best_sentence[:-1]\n",
        "\n",
        "        return \" \".join(best_sentence[start_index:])"
      ],
      "metadata": {
        "id": "qfgrMdypB7RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = NgramGenerator(unigram, bigram, trigram, quadgram)\n",
        "generation_tasks = {\n",
        "    \"Unigram\": 1,\n",
        "    \"Bigram\": 2,\n",
        "    \"Trigram\": 3,\n",
        "    \"Quadgram\": 4\n",
        "}\n",
        "\n",
        "for name, order in generation_tasks.items():\n",
        "    print(f\"\\n{'='*20} Generating for {name} Model {'='*20}\")\n",
        "\n",
        "    print(f\"\\n--- Method: Greedy Approach ---\")\n",
        "    greedy_sentences = [generator.generate_greedy(order) for _ in range(100)]\n",
        "    for i, sentence in enumerate(greedy_sentences[:3]):\n",
        "        print(f\"  {i+1}: {sentence}\")\n",
        "    if len(greedy_sentences) > 3:\n",
        "        print(\"  ...\")\n",
        "\n",
        "    print(f\"\\n--- Method: Beam Search (beam_size=20) ---\")\n",
        "    beam_sentences = [generator.generate_beam(order, beam_size=20) for _ in range(100)]\n",
        "    for i, sentence in enumerate(beam_sentences[:3]):\n",
        "        print(f\"  {i+1}: {sentence}\")\n",
        "    if len(beam_sentences) > 3:\n",
        "        print(\"  ...\")"
      ],
      "metadata": {
        "id": "nkH-0Z_6DStG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}